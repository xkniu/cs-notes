# 海量数据处理

海量数据处理的主要问题是，数据量过大，无法一次性装入内存。

海量数据处理的基本思路：

- 分而治之/hash 映射 + hash 统计 + 堆/快速/归并排序。
- 整数问题考虑是否能用 bitmap，或者使用多位 bitmap。
- 整数问题考虑能否经过双层桶划分后，内层使用 bitmap。
- 允许错误率的考虑使用 bloom filter。
- 分布式 Map Reduce 处理。

## 分而治之/hash 映射 + hash 统计 + 堆/快速/归并排序

处理的具体步骤：

1. 根据数据量，每条数据大小，估算需要的内存空间。
2. 如果需要的内存较小，直接内存里统计；如果内存较大，拆分为多个新的数据集，使得每个数据集可以放入内存。
3. 在内存中统计每个数据集的局部结果，再归并得到最终结果。

问题示例：海量日志数据，提取出某日访问百度次数前10的 IP：

1. 根据 hash 算法将原数据重新分为多个子文件，相同的 IP 会在同一个文件中。
2. 使用 HashMap 统计每个子文件的 IP 访问次数。
3. 获取每个文件的访问前 10 的 IP，然后合并每个子文件的结果。

## 整数问题考虑是否能用 bitmap，或者使用多位 bitmap

在2.5亿个整数中找出不重复的整数，注，内存不足以容纳这2.5亿个整数:

1. 使用两位 bitmap，0表示没有该数，1表示出现一次，2表示重复。2^32 * 2bit = 1G，使用 1G 的内存就可以统计所有的整数。
2. 遍历所有的数据，放入 bitmap 中。

## 整数问题考虑能否经过双层桶划分后，内层使用 bitmap

5亿个int找它们的中位数：

1. 把 int 划分为 2^16 个区域，统计每个区域内的个数，判断出来中位数落在哪个区域内，且区域内第几大的数是中位数。
2. 扫描结果所在的区域，找出第几大的数。

## 允许错误率的考虑使用 bloom filter

Bloom Filter 原理：

- 通过多个 hash 函数将数据映射到位阵列中的 n 个点，将这 n 个点设为 1.
- 判断一个数据是否在在时，如果多个 hash 函数对应的点存在 0，则它一定不在；如果都是 1，则检索的元素很可能在。
- 本质是通过极小的错误率换取空间的极大节省。

## 参考文档

- [教你如何迅速秒杀掉：99%的海量数据处理面试题](<https://blog.csdn.net/v_july_v/article/details/7382693>)
