# 分布式网站架构设计

分布式网站的核心要素：

- 性能
    - 响应时间（RT）：接受请求并返回的耗时。常用指标 TP99（Top 第99%请求的耗时）、TP90.
    - 吞吐量（Throughput）：系统在单位时间内能处理的请求量。通常系统的 `TPS=并发数/平均响应时间`。
    - 并发量：系统在同一时刻能够处理的请求量。
- 可用性：系统可用时间占总运行时间的百分比。通常使用几个9来表示，即 `99.99%`表示4个9.`5个9` 一年大约有5分钟不可以用，`4个9` 一年大约有50分钟不可用，`3个9` 一年大约有9个小时不可用。
    - 服务层，集群部署，服务的降级、幂等重试、限流熔断。
    - 数据层，数据冗余。
- 伸缩性：扩大服务规模的能力。
    - 无状态服务：集群部署，如服务多实例部署；异步化，如引入消息队列。
    - 有状态服务：数据分片（sharding），如数据库分库分表。
- 扩展性：能够简单快速地支撑新的需求。
    - 遵循设计原则，高内聚低耦合，开闭。
    - 服务化拆分，明确业务边界。
    - 消息队列解耦。
- 安全性
    - 程序安全性，框架漏洞、DDoS、XSS、CSRF、SQL 注入等。
    - 接口调用安全，认证、加密、验签。
    - 数据存储安全，如文件加密存储、密码加盐 hash 存储、敏感字段加密存储。

## 架构演化

一个分布式网关演化的流程示例：

- 纯“单机服务”，应用、存储全部使用单个服务器。
- “水平拆分”，应用存储拆分到不同服务器。
- “应用服务器集群化”，部署多台应用服务器，引入“负载均衡服务”。
- ”服务化拆分“，将服务根据业务拆分为多个独立服务，存储也拆分为独立的存储。
- ”数据水平拆分“，数据库分库分表。
- 使用“缓存”优化服务的读请求，包括本地缓存、分布式缓存、CDN 缓存等。
- 引入“搜索服务”来支持复杂的业务搜索，如引入 ES。
- ”微服务架构“，服务的拆分不断细化。
- ”容器化“，使用 K8s 部署，弹性伸缩。

总结来说，主要就是：

- 分层：服务水平拆分为多层。
- 分割：根据业务拆分为多个服务。
- 分布式集群：水平扩容，对于应用集群，无状态水平扩容；对于数据集群，有状态可以通过数据 sharding 扩容，数据 replication 高可用。
- 缓存：把数据放到链路更近的位置加速读取，如浏览器、CDN、反向代理、服务本地缓存、分布式缓存。
- 异步化：引入消息队列，提高可用性、松耦合、削峰填谷。
- 冗余：保证高可用，集群或者副本。
- 自动化：自动化伸缩、自动化监控、自动化降级、自动化预案等。
- 安全性：程序安全、接口安全、存储安全等。

高性能通用设计：

- 页面响应时间：请求合并、浏览器缓存、CSS/JS 压缩、CDN 加速、DNS 就近解析。
- 接口响应时间：网关（四层、七层）到无状态服务器（水平、垂直切分），到存储（缓存、持久化）
- 业务优化：批量获取、字段冗余。

从上往下分层来看：

- 负载均衡层：
    - DNS：GSLB，分流到就近节点。
    - LVS/F5：四层负载均衡。
    - Nginx：七层负载均。
- 应用服务：
    - 垂直拆分：服务化，根据业务不同拆分为不同的服务。
    - 水平拆分：为了应对业务的复杂性和性能要求，根据能力分层。如网关层，聚合层、核心服务层。
    - 水平扩容：集群化，每个服务部署多个实例，提供更高的吞吐，保证高可用。
    - 缓存：引入各级缓存提高处理能力，如 CDN 缓存、本地缓存、分布式缓存。
    - 异步化：通过消息队列、异步任务等方式，提高处理能力。
- 分布式缓存：
    - 通过 sharding 提高处理能力，如一致性 hash、槽分配。
    - 通过冗余（主从复制）提供高可用。
- 存储层：
    - 通过 sharding（水平分库分表）来提供伸缩性。
    - 通过冗余（主从复制）保证高可用。

## 缓存

系统各层的缓存：

- 浏览器缓存：根据响应设置的缓存参数，浏览器可以将 CSS、JS、图片等静态资源缓存。
- CDN 缓存：将一些资源分发到靠近用户的服务器缓存起来。
- 服务本地缓存：应用中的缓存，访问没有网络开销，但多个应用无法共享缓存，浪费内存且可能存在不一致。如 Guava Cache、HashMap。
- 分布式缓存：与应用分离的缓存服务，集中式缓存，多个应用可以共享缓存。如 Redis、Memcached。

缓存核心概念：

- 命中率：命中率=请求命中缓存次数/总请求次数，是衡量一个缓存有效性的最重要指标。命中率越高，说明缓存使用率越高。
- 最大空间：缓存中能放的最大元素数量，超过这个值需要进行数据淘汰。合理的空间大小有利于提高命中率。
- 淘汰策略，常见的淘汰策略有：
    - FIFO (First In First Out)：优先淘汰最老的数据。在数据实效性要求场景下可选择该类策略，优先保障最新数据可用。
    - LRU (Least Recently Used)：最近最少使用，优先淘汰最近未使用的数据，在热点数据场景下适用，优先保证热点数据的有效性。
    - LFU (Least Frequently Used)：使用频率最低，优先淘汰最近使用次数很少的数据。策略算法主要比较元素的命中次数（hit count）。在保证高频数据有效性场景下，可选择这类策略。

使用缓存常见的问题：

- 缓存穿透
    - 大量访问不存在的数据，会穿透请求到数据库，导致数据库压力过大。
    - 解决方案：
        - 缓存空的数据，可以设置一个较短的过期时间，避免缓存大量空值。
        - 使用布隆过滤器，进行简单的数据合法性过滤。
- 缓存雪崩
    - 缓存服务器宕机或者缓存大面积失效，导致大量的请求打到数据库，导致数据库压力过大。
    - 解决方案：
        - 缓存服务做高可用部署。
        - 缓存数据使用随机的过期时间，避免同一时刻大量失效。
        - 缓存预热，防止冷启动时请求大量打到数据库。
- 缓存击穿（缓存并发）
    - 当单个缓存失效时，同时存在多个并发请求会并发地从数据库加载数据，导致数据库压力过大。
    - 解决方案：
        - 缓存的加载使用互斥锁。
        - 缓存失效前，使用单个补偿线程主动重新加载数据。

缓存 hash 方案：

- 一致性 hash：将 hash 值空间组成一个虚拟环形，按照 hash 环找到对应的节点。
    - 优点：当出现节点失效时，受到影响的值较少，只有失效节点到环上的上一个节点间的 hash 值。
    - 当节点数量较少时，可以通过增加一层虚拟节点概念，将一个机器节点映射为多个虚拟机器节点，使得数据分布的更均匀。
    - 通常可以用 TreeMap 实现一致性 hash，key 为节点 hash，value 为节点信息。
- 路由表：根据路由表计算缓存应该访问哪个节点，例如 Redis cluster 的槽分配。

缓存更新的常用模式：

- Cache Aside Pattern：优先读缓存，miss 则去数据库加载，并放入缓存；写时先更新数据库，后失效缓存。这是业务系统最常用的缓存更新范式，Facebook 使用的范式。
    - 存在脏数据的可能，当线程 A 读操作 miss 后，去数据库读数据，还没放入缓存前。线程 B 更新了数据，并且失效了缓存。之后线程 A 放入了之前加载的数据，导致缓存中是旧的数据。但是出现的情况是先读数据库，但是晚于写返回，概率较低。
    - 不能避免一致性问题，只是降低了缓存中有脏数据的概率，如果需要强一致性，只能通过 2PC 或者 Paxos 来保证。因此通常还需要给缓存设置一个过期时间，来达到最终一致性，并且有强一致要求的业务不应该依赖缓存。
- Read/Write Through Pattern：应用只和缓存打交道，缓存层负责读取和写回数据到数据库。可以认为应用认为后端是一个单一的存储，而存储维护自己的 cache。
- Write Back Pattern：类似于 Linux 的 Page cache，Write Through 的一个变种，但是脏页的写回是异步的，弱一致性，存储可能丢失数据。

## 负载均衡

负载均衡指的是将负载分摊到多个服务器上，是解决高性能、可用性（单点故障）和伸缩性（集群扩容）的常用方案。

各层的负载均衡：

- GSLB (Global Server Load Balance)：DNS 层负载均衡，根据 NS 记录转给 GSLB 服务，根据用户的 IP（运营商、地区）智能的返回 LVS 的 IP。
- LVS/F5：网络协议4层负载均衡（IP+端口）。
- Nginx：网路协议7层负载均衡，转发对应的 HTTP 请求到对应的应用 server，支持 HTTP 协议，能根据域名、path 等转发。

LVS 的负载均衡模式：

- NAT：网桥模式。LVS 配置为各后端服务的网关，当收到客户端请求后修改目标 IP 为真实的后端服务，后端处理完成后返回给 LVS，LVS 再修改源 IP 为自身 VIP 后返回给用户。
    - 优点：LVS 不需要和后端在一个局域网内。每个服务器可以有自己的私有 IP。
    - 缺点：所有进出流量都需要经过 LVS，会成为性能瓶颈。
- TUN：隧道模式。后端服务器需要支持 IPTUNNEL 协议，LVS 在原数据包基础上再封装一层，目的 IP 为真实的后端服务，后端服务解包和处理后直接返回给客户端。
    - 优点：通常响应流量会大很多，LVS 不需要承担响应流量。
    - 缺点：后端服务都需要支持 IPTUNNEL，限制了后端服务只局限在部分 Linux 系统上。
- DR：直接路由模式。LVS 和后端服务在同一个交换机上，使用同一个 IP，所有请求都转发给 LVS，LVS 收到后不修改 IP 报文，将数据帧的 MAC 地址修改为后端服务器的 MAC，通过交换机发给对应的服务器。因为后端服务器 IP 和 LVS 是一样的，处理完成后直接返回客户端。
    - 优点：LVS 仅承担数据入站请求，最终后端服务器将响应数据包发回给客户端。
    - 缺点：LVS 和后端服务器需要在同一个广播域（交换机上），共享同一个 VIP 地址。


Nginx 的负载均衡策略：

- Round Robin（轮询）：依次将请求分给服务器，实现简单，均衡分配。后端服务器性能通常会有差异，均衡不一定合适。
- Weighted Round Robin（加权轮询）：带优先级的轮询，可以根据服务器性能差异设定权值。权值是静态的，不能自动调节。
- Least Connection（最少连接）：把请求分给连接最少的服务器。
- Weighted Least Connections（加权最少连接）：按照权值和连接数分配，可以根据服务器性能差异设定权值。
- Least RT（最短响应时间）：把请求分给响应最快的服务器。
- IP Hash：根据来源 IP 计算 hash，路由到对应的服务器，同样的请求会落到同一台机器上。
- Random（随机）

Dubbo 的负载均衡策略：

- RandomLoadBalance（默认）：随机负载均衡。
- RoundRobinLoadBalance：轮询负载均衡，可以根据权重轮询。
- LeastActiveLoadBalance：使用活跃连接少的进行调用。
- ConsistentHashLoadBalance：一致性 hash，当提供者宕机时，原本发往该提供者的请求，基于虚节点，平摊到其他提供者。

常用的负载均衡 Client 有 Netflix Ribbon，Spring Cloud 全家桶的一部分。

## 限流&熔断降级

限流，主要针对上游流量，服务器处理能力是有限的，通过限流来保证稳定性。

常见的限流算法：

- 计数器（固定窗口）：在计数器周期内，统计访问次数，超过则触发限流策略，下一个周期再从零开始计数。缺点是限流很不平滑。
- 滑动窗口：将时间周期分为N小份，按小份统计访问次数，根据时间滑动小份周期，总窗口超过次数则触发限流策略。滑动窗口划分的份数越多，则限流越平滑，但会占用更多的内存。
- 漏桶算法：请求到达时放入漏桶，如果漏桶已满，则触发限流策略，漏桶以固定的速率处理请求。相当于增加了一个任务处理队列，并以固定的速度处理请求，当突发流量过来时，请求处理速度不变，可能会造成处理延时。
- 令牌桶算法：以固定速率生成令牌放入令牌桶中，达到令牌桶上限则丢弃令牌，请求过来时先获取令牌，拿到令牌则执行，否则触发限流策略。令牌桶能够更好地处理突发流量，令牌产生的速度限制了吞吐量，令牌桶的大小限制了最大并发。

单机限流方案：

- 使用 AtomicLong 等实现计数器或滑动窗口。
- 使用 Guava 的 RateLimiter 来实现令牌桶限流。
    - SmoothBursty：生成令牌速率固定。
    - SmoothWarmingUp：需要对系统做预热处理时使用，令牌生成的速率先递增再稳定在固定值。

分布式限流方案：

- 配置中心 + 单机限流 SDK：通过配置中心推送各个机器的限流配置，每个机器使用单机限流来达到集群限流的效果。如果集群的流量均匀，这种方案能够达到很好的效果，因为通常限流阀值是和单机的处理能力有关，而不是和集群处理能力有关。
- Redis 限流：将滑动窗口、令牌桶之类的存储在 Redis 之类的集中存储中，来达到对集群流量限流的效果。

限流的降级策略：

- 抛出异常：返回限流错误。
- 默认值：返回降级的默认结果。
- 自定义 fallback

熔断主要针对下游调用，当下游服务不可用时，为了保护自身和保护下游，避免雪崩，将下游调用进行降级处理。业界常用的熔断组件有 Hystrix、Sentinel 等。

Hystrix 熔断器实现：

- 隔离策略
    - 信号量：使用请求线程来调用下游，通过信号量来控制调用并发量。
    - 线程池（默认模式）：调用不同下游的线程池隔离，使用新的线程来调用下游，当依赖多个下游时，线程池模式能通过异步执行提高接口性能。但是线程会增加调度、切换开销。
- 熔断器，熔断器对请求状态的统计是用滑动窗口实现的，核心状态有：
    - CLOSED：请求正常，熔断器处于关闭状态。当失败比例超过阀值，则熔断器转入 OPEN 状态。
    - OPEN：熔断器处理开启状态，请求被降级处理。延迟一定时间后，转入 HALF-OPEN 状态。
    - HALF-OPEN：半开放状态，会通过部分请求，判断请求结果。如果请求失败，重新进入 OPEN 状态；如果请求成功，进入 CLOSED 状态。

熔断器能保证当下游服务出现异常时，能快速降级返回，避免同步等待占用大量服务器资源，并对下游进行保护，并能在一段时间后尝试自动恢复。
