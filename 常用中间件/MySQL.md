# MySQL

## 数据库基础

数据库事务基本特性 ACID：

- Atomicity（原子性）：事务是最小的执行单元，事务内的操作要么一起成功提交，要么一起失败回滚。
- Consistency（一致性）：事务执行的结果使得数据库从一个一致的状态转到另一个一致的状态。如转账两个账户增减金额一定保持一致，更多的是应用上的约束。AID 都是来支持 C 的手段。
- Isolation（隔离性）：提供多事务并发操作数据的能力，隔离性能防止多事务并发执行导致的数据不一致。
- Durability（持久性）：事务处理结束后，对数据的修改就是永久的，即使系统故障也不会丢失。

并发访问中的数据读取问题：

- 脏读：读到其他事务未提交的数据。
- 不可重复读：同一个事务中，多次读取同一个记录，它的值发生变更。
- 幻读：同一个事务中，多次读取同一个记录或者范围，得到不同的结果集。读到了新插入的数据或之前读到的数据被删除。

数据库的隔离级别：

- Read Uncommitted：能读到其他事务未提交的数据，会出现「脏读」。
- Read Committed：只能读到其他事务已提交的数据，不会出现「脏读」。
- Repeatable Read：一个事务多次读取同一条的记录，一定得到相同的数据。不会出现「脏读」、「不可重复读」，会出现「幻读」。
- Serializable：事务串行化顺序执行。不会出现「脏读」、「不可重复读」、「幻读」。

常见数据库的默认隔离级别：

- Oracle：Read Committed
- MySQL：Repeatable Read，并在标准隔离级别的基础上，额外解决了幻读问题。主要使用了 MVCC 和 Gap Lock 机制来实现。

## MySQL 存储引擎

MySQL 整体可以分为 server 层和存储引擎层。

- Server 层：包括连接器、分析器、优化器、执行器等，涵盖 MySQL 的核心服务功能。
- 存储引擎层：负责数据的存储和提取，其架构模式是插件式的。

MySQL 主要的存储引擎对比：

- InnoDB：默认的存储引擎，适用于 OLTP。主要特性为，支持事务；使用行级锁；数据存储使用B+树与聚簇索引。
- MyISAM：适用于 OLAP，以读和数据插入为主的业务。不支持事务；使用表级锁；索引和数据分开存放，索引使用 B+树，叶子节点仅存所在数据页的指针。
- Memory：数据存在内存中，不进行持久化，索引使用 Hash 索引。

MySQL 使用的默认存储引擎为 InnoDB，如无特殊说明，下面主要探讨 InnoDB 引擎下的实现。

## InnoDB 文件存储&线程模型

主要的文件类型：

- `.frm` 保存每个数据表的元数据信息，包括表的定义等，`.frm` 文件与存储引擎无关，每个存储引擎都有该文件。
- 数据文件被存在表空间中，表空间是一个逻辑概念，在磁盘上存储为一个或者多个 `.idb` 文件。

表空间整体的逻辑存储结构如下：

- TableSpace（表空间）：表空间是一个逻辑容器，本质上是一个由多个磁盘文件组成的虚拟文件系统，表空间由多个段（Segment）组成。数据库由一个或者多个表空间组成，根据是否拆分进行文件存储可以分为：
  - 系统表空间：存一些数据字典、双写缓冲、变更缓冲、undo 日志等。如果没有配置独立表空间，则表数据也存在系统表空间中。
  - 独占表空间：设置 `innodb_file_per_table=ON` 后，每个数据表单独存储为 `.idb` 文件。
- Segment（段）：表空间是由段组成的，一个段包含多个区（Extent）。
- Extent（区）：区是在文件系统**连续分配**的空间，由若干个连续的页组成，区的大小为 1M。默认配置下，页的大小为16K，因此一个区有64个连续的页。
- Page（页）：页是 InnoDB 磁盘管理的最小单位，默认大小为16K，可以通过 `innodb_page_size` 来配置为`4K/8K/16K`。所有页的结构都是一样的，分为文件头（38B）、页头（56B）、最大最小记录（26B）、用户记录、页目录、文件尾（8B）。

InnoDB 线程模型：

- 默认是 One-Thread-Per-Connection 模型，即每个客户端连接生成一个线程来处理，处理完成后 sleep。
- 5.7 版本后企业版通过插件提供了 Thread Pool 线程模型，使用 epoll + 线程池模式来处理。

## InnoDB 索引

MySQL 中主要有以下几种索引：

- B+树索引：B+树是一种多路平衡查找树，其中非叶子节点只存储索引和下层节点的指针，叶子节点存储索引和数据记录。叶子节点增加对相邻叶子节点的指针，方便范围查询。
- 哈希索引：自适应哈希索引，对于被被频繁访问二级索引，在内存中自动生成哈希索引，缺点是只能支持等值查询。
- 全文索引：倒排索引实现，记录了单词到文本 id 和文本中单词位置的映射，查询语法为 `MATCH (col) AGAINST (expr)`。

索引的类别：

- 聚集索引：叶子节点存储了整行数据，即数据和索引存放是在一起的。一个表只能有一个聚集索引。默认使用主键，如果没有主键，则使用第一个非空唯一索引，如果还是没有，则使用 rowid。
- 非聚集索引：叶子节点只存放索引和主键值。使用非聚集索引查询完整数据行的时候，需要两次索引查找，先通过非聚集索引找到主键值，再回聚集索引进行查询。
- 联合索引：非聚集索引，建立在多个字段上的索引。相当于索引值是几个字段组成的元组，因此排序的时候是按照前面的字段优先，查询的时候有最左匹配原则。

索引的B+树是如何查找记录的？

- B+树的查找：通过B+树的根开始逐层查找，直到找到叶子节点，也就是对应的数据页，将数据页加载到内存中。
- 页内查找：先通过 Page Directory（稀疏索引）二分查找到对应的 slot，即粗略的记录分组，在分组内按照链表遍历的方式查找记录。在页内查找数据的时候，由于页内的数据行大小是不确定的，页内的记录是用**单向链表**形式存储的，检索效率不高，因此增加了页目录来提高查询效率。

B+树为什么适合做数据库索引？

- 相对于内存读取，硬盘读取要高几个数量级。SSD 随机读150us，HDD 磁盘寻道10ms，因此要尽量减少硬盘IO次数。局部性原理和磁盘预读，一次读取操作系统页的整数倍的数据。
- B+树对比二叉树：索引文件通常很大，主要存储在硬盘上，硬盘的读取效率比较低，因此要减少硬盘 IO 的次数，即减少索引树的高度。B+树为多路平衡查找树，高度远低于二叉树。
- B+树对比B树：B+树由于非叶子节点不保存数据，高度比B树会更低一些，因此硬盘 IO 次数更少。另外B+树进行范围查找方便，只需要找到节点后通过双向指针顺序查找就可以了，B树需要进行中序遍历。

如何估算B+树层数？

- 前置假设：已只 InnoDB 默认页大小为 16k，指针大小为 6b。假设主键使用 bigint (8b)，数据大小为 1k。
- 对于非叶子节点，一个页能存放 `16k/(8b+6b)=1170` 条数据。对于叶子节点，一个页能存放 `16k/(1k+8b)≈16`。
- 三层能存放 `1170*1170*16≈2000w` 条数据。其中第一层索引大小为16k，第二层索引大小约为16M，都很容易放到内存中。因此实际查询过程中，可能只需要一次硬盘 IO。
- 数据库到达多少数据量进行分表，主要考虑因素也是索引的层数。

什么样的字段适合作为主键？

- 大小比较小，索引树高度低，并且比较速度快，查询效率高；保证递增，这样每次插入在后面的页，减少B+树的分裂。
- 因此 UUID 就不适合作为索引，因为大小为128bit，用16进制字符保存的话，有 `128/4=32` 个字符，即索引大小为 32b，比 bigint 的 8b 大了很多。而且 UUID 生成是随机的，会造成更多的页分裂和页空间浪费。

估算数据读取时间：

- 机械硬盘：主要耗时为寻道时间和旋转延时（转动半圈的时间）。如转速为 7200 RPM，转一圈所用的时间为 `60*1000/7200=8.3ms`，则旋转延时为 4.2ms 左右。目前磁盘的平均寻道时间一般在3-15ms。
- 固态硬盘：没有寻道时间和旋转时间，一般负载非太高的时候是相对固定的值。可以按照 0.1ms 估算。

InnoDB 引擎索引优化：

- Insert buffer / change buffer：非聚集索引的插入和修改很可能是非顺序的，为了提高效率，将多个操作缓存到 buffer 里一起操作。查询的时候，需要同时查询 buffer 内的修改值和原索引树。
- Adaptive Hash Index（自适应哈希索引）：对频繁访问的二级索引，自动生成哈希索引来加速查找。自适应哈希只适合等值查询。
- MRR (Multi-Range Read) 优化：优化器将随机IO优化为顺序IO以降低查询开销。对于辅助索引的结果，放入缓冲池，缓冲池满了后对主键排序后再进行回表扫描。
- Buffer Pool LRU 冷热分离：Buffer Pool 中对于加载进来的数据，由于可能存在全表扫描和页预读机制，记录了冷数据和热数据两个 LRU 链表（5:3），如果页加载到内存 `innodb_old_blocks_time`（默认1s）后还被访问过，则由冷数据链表转入热数据链表，避免加载进来的大量新数据导致真正的热点数据被淘汰。

## 锁

InnoDB 存在多粒度锁，它允许**行级锁**和**表级锁**共存。为了方便多粒度锁冲突的判断，它还增加了表上的**意向锁**。

主要有两种类型的行锁：

- X锁（写锁、排它锁）：数据的插入/修改/删除，或者显示地加X锁 `SELECT FOR UPDATE`。
- S锁（读锁、共享锁）：显示地加S锁 `SELECT LOCK IN SHARE MODE`。

锁的兼容性与正常的读写锁一致，读锁之间互相兼容，写锁和任何锁都不兼容。

InnoDB 在添加行锁的时候，还会在对应的表上添加对应的意向锁。如行的X锁，会对表会加IX锁；行的S锁时，会对表会加IS锁。意向锁是与行锁不冲突的表级锁，意向锁之间是相互兼容的。意向锁是为了方便在需要加锁表（如 DDL 语句）时，能够快速判断冲突。意向锁是由数据库自动添加和释放的，无需人工干涉。

什么时候会加锁？

- InnoDB 中的正常的 SELECT 查询并不会加锁。除非使用 `SELECT FOR UPDATE / SELECT LOCK IN SHARE MODE` 显示地加锁。
- 正常的 `INSERT/UPDATE/DELETE` 语句都会隐式地加锁。

InnoDB 三种行锁的算法：

- Record Lock（记录锁）：加到索引记录上，锁住对应的记录。对于走聚集索引的操作，加在聚集索引上；对于走非聚集索引的操作，加在非聚集索引和其对应的聚集索引上。
- Gap Lock（间隙锁）：对于不是 UK 的非聚集索引，或者对于 UK 使用范围查询时，除了对应的记录上增加 Record Lock 外，在范围内的每个索引之间增加 Gap Lock，即避免在间隙之间增加新的数据。间隙锁用来避免幻读问题，只在 `Repeatable Read` 隔离级别下使用。
- Next-Key Lock：相当于 Record Lock + Gap Lock，锁住记录和范围。

加锁需要注意的问题：

- 对于没有走索引的操作，锁会加在整张表上。
- 避免删除不存在的数据，可能会导致间隙锁范围很大。可以优化为先查询，数据存在才删除。
- 降低隔离级别，如果业务允许，将隔离级别由 RR 降到 RC，可以有效的避免 Gap Lock

二阶段锁协议（Two-Phase Locking，2PL）：

- 在一个事务操作中，分为加锁阶段和解锁阶段。在对数据需要获取锁的操作时，申请锁；在事务的 commit/rollback 时，统一的释放前面申请的所有锁。
- 因此对于并发度最高的行（最可能产生锁冲突的行），可以尽量地放在后面操作，减少锁定的时间。

乐观锁与悲观锁，这并不是两种具体的锁，主要代表了两种加锁的行为方式：

- 乐观锁：对操作数据做乐观的假设，认为别人不会同时修改数据。操作前不加锁，只在最后更新时判断是否发生了变更。在数据库中，表增加 version 字段来实现乐观锁。
- 悲观锁：对操作数据做悲观的假设，认为别人会同时修改。先获取数据的锁，再对数据进行操作。在数据库中可以用 `SELECT FOR UPDATE` 来实现悲观锁。

乐观锁更加适用于竞争不激烈的场景，如果并发很高，很多时候都发生冲突，应该使用悲观锁来避免无效的业务处理。在实际业务中，可以考虑同时使用乐观锁和悲观锁，因为乐观锁通常实现在数据访问层，比较偏底层，更加容易封装，不容易漏加锁，用来确保数据的一致性；而乐观锁通常在更高的业务层，加锁的位置比较分散，容易漏，并且锁的粒度不好选择，但是可以用来限制场景的并发，从根本上避免并发问题。

## 事务

MySQL 的事务通过 redo log、undo log、锁机制、MVCC 来实现的。

- 事务的原子性是通过 undo log 来实现的。
- 事务的隔离性是通过读写锁、MVCC来实现的。
- 事务的持久性是通过 redo log 来实现的。
- 事务的一致性通过其他三个特性来达到。

Redo log 和 undo log 使用的是 Aries 算法。基本上所有的 DB 都是用 Aries 算法做 recovery，或者使用它的变种。它的核心思想如下：

- Write-Ahead Logging：对内存做的修改，都以 log 形式在 data 前刷盘。
- Redo/Undo：重启时，对所有已提交的事务做 redo；对未提交的事务做 undo。
- Aries 使用的前提是数据库的刷盘是 Steal + No-Force 的。虽然使用 No-Steal + Force 是最简单的策略，但是硬盘操作效率太低。
  - Steal：允许未提交的 dirty data 刷到磁盘
  - No-Force：允许已提交的事务 data 不立刻刷到磁盘
- Checkpoint 机制避免 WAL 无限增长。

Redo log 的实现原理：

- 本质是一种 WAL 技术，即在数据文件修改前，先记录修改日志。日志文件是顺序 IO，数据文件是随机 IO，日志文件的写入效率很高。
- Redo log 由内存中的 redo log buffer 和物理文件 redo log file 组成。日志记录的是物理日志，是对某页的偏移量的修改，日志格式为 type、space id、page number、data。
- Redo log 是为了在宕机时，恢复没有刷回磁盘的脏页，因此对于已经刷回磁盘的数据页的 redo log，可以进行删除。所以 redo log 文件不需要特别大，可以循环使用。默认配置是循环地使用了两个文件（`ib_logfile0/ib_logfile1`），文件默认大小是48M。
- Redo Log 和数据页上都有 LSN（Log Sequence Number），如果 redo log 中的 LSN 比对应数据页中的大，说明该数据脏页没有刷回，需要恢复该数据页。Checkpoint 指的是该 LSN 前的脏页都已刷回，前面的 redo log 可以进行删除了。
- redo log buffer 不需要写入一条立刻刷盘，但需要保证它的数据页写回前必须刷盘。另外根据可靠性和性能，有以下几种刷盘策略：
  - 1：事务提交必须写入文件，并调用 fsync 刷盘。
  - 0：事务提交不立刻写入磁盘，而是由 master thread 定时写入。
  - 2：事务提交必须写入文件（系统缓冲区），不调用 fsync 刷盘。

Redo log 用来恢复页的数据，但是必须要保证页的数据是完整的，即脏页的写回是原子的，不能只写了一半回去。InnoDB 通过 double write 技术来保证页的完整性：

- 脏页的刷盘，不直接写回，而是写入内存的 `double write buffer`（大小为2M），然后将 `double write buffer` 中的页，每次1M地写入共享表空间的物理磁盘上（由于是顺序写，效率很高），之后再分别写回页文件。因为操作系统的页大小为4K，如果直接将页写回，可能只写回了页的部分数据（partial page write）而宕机，造成页的不完整，不完整的页是不能用 redo log 进行恢复的。这里相当于先把数据写在另外的地方（备份），写完后再去写原数据，这样当原数据不完整时，可以先去备份恢复。

Undo log 的实现原理：

- Undo log 本质上是一种逻辑日志，更像是备份数据，而不是日志。对于事务中页中修改的记录行，通过链表记录修改的每个版本（实际上记录的是反操作）。
- Undo log 只对事务中有用，当事务结束后数据已经持久化了，可以进行删除。对于 insert 操作，事务提交后，可以立刻删除 undo log；对于 update/delete 操作，由于 MVCC 机制，需要等之前的事务都结束后才能删除，先添加到 undo log 链表中，之后由 purge 线程进行删除。
- 由于数据页上已经做了修改，但是后续这部分修改可能需要回滚（事务回滚时），所以 undo log 也需要持久化。Undo log 记录存储在回滚段中，也存在随机IO问题。可以将 Undo log 也看做是数据，它也会用 redo log 来记录修改，通过 WAL 顺序IO来提高效率。
- Undo log 和 redo log 的修改都可以是在内存中的，只需要保证事务提交前 redo log 落盘就可以了。宕机恢复的时候，根据 redo log 中事务是否提交，对数据页进行重做或者回滚。

一定需要 redo log 和 undo log（这里指的是 undo log 文件）吗？

- 从实现事务上来说，使用 No-Steal + Force 策略，则不需要。事务提交，数据一定写入磁盘，不能在内存中慢慢刷回，就不需要 redo Log；如果事务没提交，数据一定只能在内存中，不能刷回磁盘，则不需要 undo Log。
- 但由于数据页写回是随机 IO，效率较低，而 redo log 日志的写回是顺序 IO，因此需要 redo log；使用 undo log，则事务没提交时数据页就允许写入磁盘，这样事务提交时写入数据很少，不用把数据都积累到事务提交前写入。因此使用 redo log 和 undo log 机制刷盘效率最高。

MVCC 的实现依赖的是 undo log 与 read view：

- Undo log：用来记录数据的多个版本数据。
- Read view：用来判断 undo log 版本链中数据对事务的可见性。Read view 记录了当前活跃的事务列表 `m_ids`，`min_trx_id` 为最小的活跃事务 id，`max_trx_id` 为准备分配给下一个事务的 id，`creator_trx_id` 为自己的事务 id。事务只能看到当前已提交事务的数据或自己事务修改的数据。具体的可见性规则如下：
  - 等于 `creator_trx_id`，说明这个数据是自己修改的，可以看到。
  - 小于 `min_trx_id`，说明这个数据的事务已经提交，可以看到。
  - 大于 `max_trx_id`，说明这个数据的事务在当前事务后开启，不能看到。
  - 在 `min_trx_id` 和 `max_trx_id` 之间，但是不属于 `m_ids` 列表中的事务，说明这个数据的事务在当前事务开始时，已经提交，可以看到。

根据数据库的隔离级别，生成 read view 的时机不同：

- Read Uncommitted：不生成 read view，最接读最新的版本。
- Read Committed：每次执行查询语句的时候，生成 read view。
- Repeatable Read：第一次执行查询语句的时候，生成 read view。
- Serializable：使用加锁的方式访问记录。

在 MVCC 并发控制中，读可以分为两类：

- 快照读：读取的是记录的某个快照版本，不用加锁。正常的 `SELECT 查询`都是快照读。
- 当前读：读取的是记录的最新版本，并加上锁，保证其他事务不会再修改这条记录。`INSERT/UPDATE/DELETE 语句`中的读，`SELECT FOR UPDATE / SELECT LOCK IN SHARE MODE` 中的读，都为当前读。

事务的锁机制，参考前面的“锁”章节。

## 主从同步

MySQL 通过 binlog 的复制来实现主从同步。主要的过程如下：

- 主库会生成 binlog log dump 线程（和从库数量对应），用于给从库 IO 线程传 binlog。
- 从库会有两个线程，IO thread 读取主库 binlog，并写入到本地的 relay log；SQL thread 读取 relay log，并解析成为 SQL 执行。

Binlog 有三种格式：

- Statement：记录更改数据的 SQL，不需要每行的变化。优点是日志量较小，性能高，缺点是对于不确定的语句操作（如 `UUID()`），不会写入日志和复制。
- Row：记录每一行数据的更改，优点是所有修改都能复制，缺点是数据量大，性能低，容易出现主从同步延时。
- Mixed：一般的语句用 statement 记录；对于 statement 无法完成的，使用 row 格式保存。但还是有一定可能出现不一致。

MySQL 5.1.5 之前只支持 statement 格式；5.1.5 开始支持 row 格式。5.7.7 开始将默认值由 statement 改为了 row。

Binlog 的格式与隔离级别：

- Statement 格式复制，在 RC 模式下可能出现主从不一致，因为没有间隙锁，从库复制的顺序可能和主库执行的顺序不一致。所以低版本的 MySQL 默认的隔离级别是 RR。
- Row 格式复制，对于 RC 和 RR 都不会有主从不一致的问题。因此处于数据准确性考虑，应该使用 row 格式。

MySQL 的复制方式：

- 异步复制：Master 写完 binlog 就处理提交操作，不管 slave 状态。效率最高，但很可能出现数据不一致。
- 全同步复制：Master 提交事务后，所有的从库都执行了该事务，才返回给客户端。效率太低。
- 半同步复制：Master 等待一个从节点收到并且写入 relay log 后，返回给客户端。半同步复制如果超过配置的超时时间，会退化为异步复制，等 slave 追上后再恢复半同步复制。如果希望保持数据强一致（牺牲可用性，从库都挂了则不允许主库执行），可以把超时时间配置为无限长。

一个事务在半同步模式下提交，主要有4个阶段：

1. Redo log write (prepare)
2. Binlog flush to disk
3. Redo log commit
4. Send binlog to slave

半同步复制有两种配置：

- after_commit：Master commit 事务后，等 slave 写入 relay log 后，应答客户端。对于4个阶段的顺序为 `1->2->3->4`，但是3完成后，其他事务的查询已经能查到该事务的数据，如果这时候 master crash，其他事务在 slave 上又查不到这部分的数据，出现了幻读。
- after_sync（又叫 Lossless Replication）：master 等 slave 写入 relay log 后，再 commit 事务，应答客户端。对于4个阶段的顺序为 `1->2->4->3`，这样可以保证数据不丢失，性能因为组提交，并没有变差。

主从切换后的处理方式：

- 如果2阶段完成后 master crash，这时候从库没有这部分数据，但是 master 启动后 recovery 会根据 binlog 提交当前事务，会出现数据不一致，因此主库宕机恢复后不能作为从库加入原集群，需要重做。
- 对于应用来说，没有收到 commit 成功的信息，认为事务提交失败。但 slave 提升为主库后，这部分事务可能已提交成功，因此业务不能盲目重试，不然可能会重复插入数据、多次更新数据。而应该当做事务失败，按正常的逻辑重新处理整个业务。

Redo log 和 binlog 的区别：

- Redo log 是 InnoDB 引擎特有的；Binlog 是 MySQL server 实现的，所有引擎都可以使用。
- Binlog 是逻辑日志，记录了语句的原始逻辑；Redo log 是物理日志，记录了对数据页的修改。
- Redo log 是循环写的，会覆盖以前的日志；Binlog 是追加写的，不会覆盖以前的日志。
- Redo log 提供了 crash-safe 能力；Binlog 不具有 crash-safe 能力，因为它判断不出来哪些脏页已经刷盘。

为了保证主从库的一致性，需要保证 redo log 和 binlog 的数据一致性。MySQL 使用了两阶段提交来实现，先写入 prepare 的 redo log，然后写入 bin log，再写入一条 commit 的 redo log。因此使用 redo log 进行事务恢复的时候，需要根据 binlog 的状态来确认 prepare 状态的 redo log 是否要进行提交。

## MySQL 集群

MySQL 集群的常用方案：

- MMM (Master-Master replication manager for MySQL)：Google 团队开发的比较老的一款高可用产品，业界用的不多。数据库使用多主多从，部署 mmm 服务（manager/agent 架构），MySQL 节点部署 agent 上报节点状态，每个节点均使用 VIP 连接，出现故障后 manager 负责主从的切换和 VIP 的切换。
- MHA (MySQL Master High Availability)：Facebook 开发的高可用组件。数据库使用一主多从的结构，之间使用异步或者半同步复制。部署一套 MHA Manager 监控主库状态，出现问题后自动自动完成 VIP 切换。
- MGR (MySQL Group Replication)：MySQL 内核提供的强一致方案，通过 Paxos 协议实现强一致性，保证同一个组内数据的一致性。但是 MGR 只是数据的强一致高可用技术，它不是切换方案，为了对应用透明，通常还是要基于 VIP 漂移，或者通知新的结果给监控服务再通知给客户端，还需要辅助开发很多工具和脚本。

基本思路和共同点：

- 对主从集群中 master 进行监控。
- 通过 VIP 实现 master 故障切换。
- 重新配置其他 slave 对 master 的同步。

MMM 方案：

- 原理：
  - 数据库使用多主方案。部署 mmm-manager，并在每个节点部署 mmm-agent，agent 上报数据库节点状态到 manager。每个数据库节点都需要 VIP，主挂了后 manager 进行主主切换，并提升某个 slave 为新的主，完成 VIP 的漂移。
- 缺点：
  - VIP 数量过多，管理困难。
  - Agent 本身没有高可用，挂掉后导致 manager 误判。
  - Manager 存在单点问题。

MHA 方案：

- 原理：
  - 部署正常的一主多从结构的数据库，数据库直接使用半同步或者异步复制。主库使用 VIP 访问。
  - 部署 MHA Manager 检测主从库状态，主库出现问题后，将最新从库提升为主库，并将主库 VIP 漂移到新的 master。
- 优点：
  - 成熟稳定，在业界用的比较多。
  - 可以自动的故障检测和转移，一整套的切换方案。
- 缺点：
  - 半同步复制极端情况下可能出现数据一致性问题。
  - MHA Manager 的单点问题。

MHA 高可用的一些优化：

- 去 VIP：由于 VIP 只能实现在同一个网段或者说同一个二层交换机下，无法做到跨机房或者跨机房的高可用。可以 MHA 切换后通知一个 Monitor 服务，服务更改 ZK 上的 IP 信息，客户端监听 IP 变化。这样就可以做到去 VIP 化。
- 主从复制丢失：尽量使用半同步复制，保证95%场景数据的一致性。可以专门部署一台 binlog server，模拟 slave 接受日志，部署在 master 就近的物理节点上，保证数据快速落地。当出现故障时，使用该 server 做数据恢复。
- MHA Manager 单点：支持集群化，部署高可用集群，做 leader 选举。

MGR 方案：

- 原理：
  - 通过 MySQL 插件支持，无需额外的管理器节点。
  - 若干个节点组成一个复制组，事务的提交通过 paxos 协议，超过半数节点通过才能提交。
  - 只提供了数据的强一致高可靠方案，不是一整套切换方案。
- 优点：
  - 避免了脑裂问题。
  - 支持多主模式，不过官方推荐单主模式。
  - 数据可靠性高，通过 paxos 复制 binlog 到了超过半数节点。没有超过半数的事务不会被提交，成员宕机后不需要特殊处理就可以加入组。
- 缺点：
  - 存在一定的限制，如只支持 InnoDB 存储引擎、每个表必须有主键、只能在 GTID 模式下运行。
  - 每次主库写入，需要大多数节点 ACK，存在一定的响应时间开销。
  - 必须要有奇数个节点，原先一主一从，现在至少需要3台，存在一定资源浪费。

## 数据类型

- 整数类型：`TINYINT/SMALLINT/MEDIUMINT/INT/BIGINT` 分别使用 `1/2/3/4/8` 个字节存储，`int(11)` 里只的是显示宽度，不是精度。
- 浮点数：`FLOAT/DOUBLE` 使用 `4/8` 个字节存储，能表示比较大的范围，但是存在精度丢失，有效数字分别为 `7/16` 位。`DECIMAL(m, n)` 表示定点数，m 表示总数字位数，n 表示小数最长位数，占用空间为将整数和小数分开存储，每9位占4个字节，小数点位置一个字节。
- 字符串：`CHAR(n)` 固定位数字符串，n为字节数，最大为 255，存储后不够的填充空格，查询时尾空格会删除；`VARCHAR(n)` 变长字符串，n为字符长度，最大为 65535，还需要1或2字节用来存储长度，尾空格会保留。
- 日期&时间：`DATETIME` 可以表示 1000~9999 年的日期和时间，使用8字节存储，存储的相当于本地（墙上）时间；`TIMESTAMP` 使用4字节存储，unix 时间戳，最大能到 2038 年，存储的为物理时刻（与时区无关）。5.7 版本后，都增加了小数位，可以保存到毫秒。

## 数据库优化

执行计划分析，通过 `explain` 命令来查询执行计划。结果字段解释：

- select_type: 查询类型，有简单查询、联合查询、子查询等。
- type: 访问类型。通常来说性能关系：`const > eq_ref > ref > range > index > all`，具体含义如下：
  - const：主键键或者uk的等值查询
  - eq_ref：连表 join 唯一索引
  - ref：连表 join 非唯一索引
  - range：索引范围查询
  - index：全索引扫描
  - all：全表扫描
- possible_keys：查询时可能用到的索引。
- key：实际使用的索引。
- key_len：使用了索引的字节数，可以评估组合索引是否完全被使用。
- rows：估算找到结果要读取的行数，这个值通常越小越好。
- extra：解决查询的详细信息。常用的信息有
  - Using index：索引覆盖，不需要再回表扫描。
  - Using where; Using index：索引覆盖，但是还需要在索引上过滤
  - Using index condition：索引过滤后，再回表扫描。
  - Using where：需要回表扫描。
  - Using filesort：不能通过索引排序，需要额外的排序操作。

索引的优化：

- 对区分度高（`count(distinct column) / count(1)`）的列建立索引。
- 建立组合索引时，考虑最左匹配原则和区分度，将能覆盖更多查询和区分度高的列建在前面。
- 索引覆盖扫描：对于频繁且只需要部分字段的查询，建立组合索引，让通过组合索引就能获取全部需要的字段，避免回（聚集索引）表扫描（随机 IO 会慢很多）。
- 尽量减少索引列的长度。字符很长的列需要索引时，可以考虑模拟哈希索引，如对于 `url`，再增加一列 `url_crc` 来建立索引。或者使用前缀索引，来控制索引的长度。
- 三星索引，一个索引能够满足查询中的 `where / order by / column` 就是三星索引，其中分别为了减少扫描数据行，避免排序，避免回表扫描。设计索引的时，可以考虑尽量提高索引的星级。

查询的优化：

- 查询时，只查询必要的字段；使用 limit 只返回需要条数的数据。
- 查询语句中，不要对索引列应用函数，而是在查询的值上应用。
- 如果某个查询走的索引不太合适（通常数据库优化的都比较好），可以用 Index Hint 来强制指定索引。
- 分页查询的时候，较大页建议不要直接使用 `limit [offset,] rows` 语法，因为这样会从聚簇索引的第一条开始遍历，遍历到 offset 后再开始获取数据。
  - 优先优化为 `id > ${lastMaxId} limit n`，这样变成索引查询，速度很快。但是需要业务保存上一页的最大 id，主要看业务交互是否能够接受不支持获取第几页数据的语义；通常分页处理全量数据都使用这种方式。
  - 优化为先通过 `select id limit n, 1` 的子查询查询出来一个 id，然后根据 `select * where id > x limit n` 来查询。这个能够提高速度的原因主要是因为 `select id` 比 `select *` 快很多。
- 拆分大事务，减少事务的范围，减少锁定的数据量和时间。
- 对重复的查询，业务做缓存。应用层来做数据 join，方便数据库分库分表，数据分开做原子的缓存，而不是缓存 join 的结果，也能够提高缓存的利用率。

## 参考文档

- 《MySQL技术内幕：InnoDB存储引擎》：<https://book.douban.com/subject/24708143/>
- 事务是如何实现的？Undo Log 原理：<https://blog.51cto.com/u_12054307/2378652>
- 图解数据库 Aries 事务 Recovery 算法：<https://my.oschina.net/fileoptions/blog/2988622>
- after_sync vs after_commit，哪个性能更好？<https://mp.weixin.qq.com/s/gHn0jf_-klZO3x0yZJFHIQ>
- 美团数据库高可用架构的演进与设想：<https://tech.meituan.com/2017/06/29/database-availability-architecture.html>
